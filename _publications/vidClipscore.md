---
title: "Evaluation of Automatically Generated Video Captions Using Vision and Language Models"
collection: publications
permalink: /publication/vidClipscore
excerpt: 'Vision and language models are easily transferred to other tasks. In particular, they have been demonstrated to work well in the evaluation of automatic image captioning. This has made it possible to evaluate systems without the need for references or additional information apart from the image and the caption. However, these models do not provide a straightforward way of evaluating videos. In this paper, we propose using these models for video captioning evaluation. We explore the use of both single image-based evaluation and different methods to include data from multiple frames. Experiments demonstrate that using clustering methods to select a few frames to compute the final score gives an excellent correlation with human judgment. The bias in the human annotations can also influence the metric, so we propose filtering the human assessments to discard outliers and improve the evaluation process.'
date: 	2022-10-28
venue: '2022 IEEE International Conference on Image Processing (ICIP)'
paperurl: 'https://ieeexplore.ieee.org/abstract/document/9897559/'
citation: 'Lebron, Luis, et al. "Evaluation of Automatically Generated Video Captions Using Vision and Language Models." 2022 IEEE International Conference on Image Processing (ICIP). IEEE, 2022.'
---
Vision and language models are easily transferred to other tasks. In particular, they have been demonstrated to work well in the evaluation of automatic image captioning. This has made it possible to evaluate systems without the need for references or additional information apart from the image and the caption. However, these models do not provide a straightforward way of evaluating videos. In this paper, we propose using these models for video captioning evaluation. We explore the use of both single image-based evaluation and different methods to include data from multiple frames. Experiments demonstrate that using clustering methods to select a few frames to compute the final score gives an excellent correlation with human judgment. The bias in the human annotations can also influence the metric, so we propose filtering the human assessments to discard outliers and improve the evaluation process.

[Download paper here](https://ieeexplore.ieee.org/abstract/document/9897559/)

Recommended citation: 

@inproceedings{lebron2022evaluation,
  title={Evaluation of Automatically Generated Video Captions Using Vision and Language Models},
  author={Lebron, Luis and Graham, Yvette and Oâ€™Connor, Noel E and McGuinness, Kevin},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)},
  pages={2416--2420},
  year={2022},
  organization={IEEE}
}
