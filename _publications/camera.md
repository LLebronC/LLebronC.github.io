---
title: "Desarrollo de camara multiespectral: captura y analisis de sus imagenes"
collection: publications
permalink: /publication/camera
excerpt: 'Traditionally the image classification and recognition have been done using grey or color images in the boundaries of the human eye, which is between the 400 mm and the 700nm, these limits produce a reduction of the information which a machine can perceive. The objective of this project is to study the effect of these images on the object clasificacion problem. The first goal of the project is to adapt a multiespectral camera cheaper than the ones that are being sold nowadays. This camera will be made using one Arduino, a black and white camera and some LED of different spectrums. The second part will consist in the study and comparison of some clasificacion algorithms in different color spaces and feature descriptors, giving the output of the multiespectral camera.'
date: 	2016-06-28
venue: "Thesis Bachelor's degree"
paperurl: 'https://ddd.uab.cat/record/165143'
citation: 'Lebron Casas, Luis. "Desarrollo de camara multiespectral: captura y analisis de sus imagenes."'
---
Traditionally the image classification and recognition have been done using grey or color images in the boundaries of the human eye, which is between the 400 mm and the 700nm, these limits produce a reduction of the information which a machine can perceive. The objective of this project is to study the effect of these images on the object's clasificación problem. The first goal of the project is to adapt a multiespectral camera cheaper than the ones that are being sold nowadays. This camera will be made using one Arduino, a black and white camera and some LED of different spectrums. The second part will consist in the study and comparison of some clasificación's algorithms in different color spaces and feature descriptors, giving the output of the multiespectral camera.	Evaluating video captioning systems is a challenging task as there are multiple factors to consider; for instance: the fluency of the caption, multiple actions happening in a single scene, and the human bias of what is considered important. Most metrics try to measure how similar the system generated captions are to a single or a set of human-annotated captions. This paper presents a new method based on a deep learning model to evaluate these systems. The model is based on BERT, which is a language model that has been shown to work well in multiple NLP tasks. The aim is for the model to learn to perform an evaluation similar to that of a human. To do so, we use a dataset that contains human evaluations of system generated captions. The dataset consists of the human judgments of the captions produces by the system participating in various years of the TRECVid video to text task. BERTHA obtain favourable results, outperforming the commonly used metrics in some setups.

[Download paper here](https://ddd.uab.cat/pub/tfg/2016/tfg_49267/Desarrollo_de_camara_multiespectral_captura_y_analisis_de_sus_imagenes-Luis_Lebron_Casas.pdf)	

Recommended citation:	

@article{lebrondesarrollo,	
  title={Desarrollo de camara multiespectral: captura y analisis de sus imagenes},	
  author={Lebron Casas, Luis}	
}
